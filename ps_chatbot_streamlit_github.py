import os
import glob
import streamlit as st
import time
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# Page configuration
st.set_page_config(
    page_title="ForteBank RAG Chatbot",
    page_icon="üè¶",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Load environment variables
@st.cache_resource
def load_environment():
    # Try to load local .env file (for development)
    env_path = "/home/nurbek/Forte/payment_systems/code/env_variables.env"
    if os.path.exists(env_path):
        load_dotenv(env_path)
    
    # For Streamlit Cloud, get from st.secrets or environment
    return {
        "DATA_PATH": st.secrets.get("DATA_PATH", os.getenv("DATA_PATH", "./data")),
        "CHROMA_PATH": st.secrets.get("CHROMA_PATH", os.getenv("CHROMA_PATH", "./chroma_db")),
        "OPENAI_API_KEY": st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY"))
    }

# RAG Template
RAG_TEMPLATE = """–¢—ã - –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–ª–∞—Ç–µ–∂–Ω—ã—Ö —Å–∏—Å—Ç–µ–º ForteBank. –ö —Ç–µ–±–µ –æ–±—Ä–∞—â–∞—é—Ç—Å—è —Å —Ä–∞–∑–Ω—ã—Ö —Ñ–∏–ª–∏–∞–ª–æ–≤ –±–∞–Ω–∫–∞ —Å —Ä–∞–∑–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏, —Ç—ã –¥–æ–ª–∂–µ–Ω –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–ø—Ä–æ—Å, —Å—Ç—Ä–æ–≥–æ –ø—Ä–∏–¥–µ—Ä–∂–∏–≤–∞—è—Å—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π.
    –î–∞–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: 
    {context}

    # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
                - –í—Å–µ —Ç–≤–æ–∏ –æ—Ç–≤–µ—Ç—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
                - –ù–µ –ø–∏—à–∏ "–æ—Ç–≤–µ—Ç" –∏–ª–∏ –¥—Ä—É–≥–∏–µ —Å–ª–æ–≤–∞ –ø–µ—Ä–µ–¥ —Å–∞–º–∏–º –æ—Ç–≤–µ—Ç–æ–º, —Å—Ä–∞–∑—É –ø–∏—à–∏ —Å–∞–º –æ—Ç–≤–µ—Ç
                - –ü–æ–∑–¥–∞—Ä–æ–≤–∞–π—Å—è —Å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–º —Ñ–∏–ª–∏–∞–ª–∞ –≤ –¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ–π –º–∞–Ω–µ—Ä–µ
                - –ü–µ—Ä–µ–¥ —Ç–µ–º –∫–∞–∫ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –≤–æ–ø—Ä–æ—Å –∏ —Å—Ä–∞–≤–Ω–∏ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º.
                    - –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –∫–ª–∏–µ–Ω—Ç–∞, —Ç–æ –ª—é–±–µ–∑–Ω–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –µ–≥–æ.
                    - –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å —Å—Ö–æ–∂–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–∞ —Ç–µ–º—É –≤–æ–ø—Ä–æ—Å–∞ –∫–ª–∏–µ–Ω—Ç–∞, —Ç–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –µ—ë –∏ —É—Ç–æ—á–Ω–∏, —ç—Ç–æ—Ç –ª–∏ –æ—Ç–≤–µ—Ç —Ö–æ—Ç–µ–ª –∫–ª–∏–µ–Ω—Ç.
                    - –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å—Ö–æ–∂–∞—è —Å —Ç–µ–º–æ–π –≤–æ–ø—Ä–æ—Å–∞ –∫–ª–∏–µ–Ω—Ç–∞, —Ç–æ –æ—Ç–≤–µ—Ç—å –∫–∞–∫ –≤ –ø—Ä–∏–º–µ—Ä–∞—Ö —Ñ—Ä–∞–∑ –Ω–∏–∂–µ.
                - –í–µ–∂–ª–∏–≤–æ –æ—Ç–∫–∞–∑—ã–≤–∞–π –≤ —Å–ª–µ–¥—É—é—â–∏—Ö —Å–ª—É—á–∞—è—Ö:
                    - –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ –∫–∞—Å–∞–µ—Ç—Å—è —Ç–µ–º, –Ω–µ—Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –ø–ª–∞—Ç–µ–∂–Ω—ã–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏.
                    - –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ –∫–∞—Å–∞–µ—Ç—Å—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∏–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è —Ç–≤–æ–µ–≥–æ –æ—Ç–≤–µ—Ç–∞.
                    - –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç —É—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç, —á—Ç–æ –≤ —Ç–≤–æ–µ–º –æ—Ç–≤–µ—Ç–µ –æ—à–∏–±–∫–∞.
                - –°–æ—Ö—Ä–∞–Ω—è–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π, –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π —Ç–æ–Ω –≤–æ –≤—Å–µ—Ö –æ—Ç–≤–µ—Ç–∞—Ö.
                - –°—Ç–∞—Ä–∞–π—Å—è –¥–∞–≤–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω—ã–µ –∏ –¥–µ—Ç–∞–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã

                # –ü—Ä–∏–º–µ—Ä—ã —Ñ—Ä–∞–∑
                ## –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
                - –Ø –Ω–µ —Ä–∞—Å–ø–æ–ª–∞–≥–∞—é —Ç–æ—á–Ω—ã–º–∏ —Å–≤–µ–¥–µ–Ω–∏—è–º–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É. 
                - –≠—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ —Ä–∞–º–∫–∏ –º–æ–∏—Ö —Ç–µ–∫—É—â–∏—Ö –∑–Ω–∞–Ω–∏–π.  
                - –ú–Ω–µ –∂–∞–ª—å, –Ω–æ —è –Ω–µ –º–æ–≥—É –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –≤–∞–º —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. 

                ## –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–µ—â–µ–Ω–Ω–æ–π –∏–ª–∏ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π —Ç–µ–º—ã
                - ¬´–ú–Ω–µ –æ—á–µ–Ω—å –∂–∞–ª—å, –Ω–æ —è –Ω–µ –º–æ–≥—É –æ–±—Å—É–∂–¥–∞—Ç—å —ç—Ç—É —Ç–µ–º—É. –ú–æ–∂–µ—Ç –±—ã—Ç—å, —è –º–æ–≥—É –ø–æ–º–æ—á—å –≤–∞–º –≤ —á–µ–º-—Ç–æ –¥—Ä—É–≥–æ–º?¬ª
                - ¬´–Ø –Ω–µ –º–æ–≥—É –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É, –Ω–æ —è –±—É–¥—É —Ä–∞–¥ –ø–æ–º–æ—á—å –≤–∞–º —Å –ª—é–±—ã–º–∏ –¥—Ä—É–≥–∏–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏¬ª.

    –í–æ–ø—Ä–æ—Å: {question}
    """

@st.cache_data
def load_all_documents(data_path):
    """Loads all PDF documents from the specified data path including subdirectories."""
    all_documents = []
    pdf_files = glob.glob(os.path.join(data_path, "**/*.pdf"), recursive=True)
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, pdf_path in enumerate(pdf_files):
        try:
            status_text.text(f"Loading {os.path.basename(pdf_path)}...")
            loader = PyPDFLoader(pdf_path)
            documents = loader.load()
            all_documents.extend(documents)
            progress_bar.progress((i + 1) / len(pdf_files))
        except Exception as e:
            st.error(f"Error loading {pdf_path}: {str(e)}")
    
    status_text.text(f"Loaded {len(all_documents)} total pages from {len(pdf_files)} PDF files")
    return all_documents

def split_documents(documents):
    """Splits documents into smaller chunks."""
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len,
        is_separator_regex=False,
    )
    all_splits = text_splitter.split_documents(documents)
    return all_splits

@st.cache_resource
def get_embedding_function():
    """Initializes OpenAI embeddings using text-embedding-3-small model."""
    env_vars = load_environment()
    if not env_vars["OPENAI_API_KEY"]:
        st.error("OPENAI_API_KEY environment variable not set.")
        st.stop()
    
    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-small",
        dimensions=1536
    )
    return embeddings

@st.cache_resource
def get_vector_store(persist_directory):
    """Initializes or loads the Chroma vector store."""
    embedding_function = get_embedding_function()
    
    if os.path.exists(persist_directory):
        vectorstore = Chroma(
            persist_directory=persist_directory,
            embedding_function=embedding_function
        )
        return vectorstore
    else:
        return None

def index_documents(chunks, embedding_function, persist_directory):
    """Indexes document chunks into the Chroma vector store."""
    with st.spinner("Indexing documents... This may take a few minutes."):
        vectorstore = Chroma.from_documents(
            documents=chunks,
            embedding=embedding_function,
            persist_directory=persist_directory
        )
        vectorstore.persist()
    return vectorstore

@st.cache_resource(
    hash_funcs={Chroma: lambda _: None}   # ignore hashing for Chroma instances
)
def create_rag_chain(vector_store, openai_model="gpt-3.5-turbo", temperature=0):
    """Creates the RAG chain with OpenAI's ChatGPT."""
    env_vars = load_environment()
    if not env_vars["OPENAI_API_KEY"]:
        st.error("OPENAI_API_KEY environment variable not set.")
        st.stop()
    
    llm = ChatOpenAI(
        model=openai_model,
        temperature=temperature
    )

    retriever = vector_store.as_retriever(
        search_type="similarity",
        search_kwargs={'k': 3}
    )

    prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)

    rag_chain = (
        {"context": retriever, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )
    return rag_chain

def main():
    st.title("üè¶ ForteBank RAG Chatbot")
    st.markdown("–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ —Å–∏—Å—Ç–µ–º—É –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –ø–ª–∞—Ç–µ–∂–Ω—ã—Ö —Å–∏—Å—Ç–µ–º ForteBank!")

    # Load environment variables
    env_vars = load_environment()
    
    # Sidebar for configuration
    with st.sidebar:
        st.header("üìä –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã")
        
        # Check if vector store exists
        if env_vars["CHROMA_PATH"] and os.path.exists(env_vars["CHROMA_PATH"]):
            st.success("‚úÖ –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            vector_store_exists = True
        else:
            st.warning("‚ö†Ô∏è –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            vector_store_exists = False
        
        # Rebuild vector store button
        if st.button("üîÑ –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"):
            rebuild_vector_store(env_vars)
        
        st.markdown("---")
        st.markdown("**–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:**")
        st.markdown(f"üìÅ –ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º: `{env_vars['DATA_PATH']}`")
        st.markdown(f"üóÉÔ∏è –ü—É—Ç—å –∫ –±–∞–∑–µ: `{env_vars['CHROMA_PATH']}`")

        st.markdown("---")
        # 1) Show all indexed PDFs
        st.header("üìÑ –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ PDF")
        if env_vars["DATA_PATH"]:
            pdf_files = glob.glob(
                os.path.join(env_vars["DATA_PATH"], "**/*.pdf"),
                recursive=True
            )
            if pdf_files:
                for pdf in pdf_files:
                    # display relative path so it‚Äôs not too long
                    rel = os.path.relpath(pdf, env_vars["DATA_PATH"])
                    st.text(f"‚Ä¢ {rel}")
            else:
                st.text("‚Äî –ù–µ—Ç PDF-—Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è ‚Äî")
        else:
            st.text("–ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω.")

        st.markdown("---")
        # 2) Allow user to upload new PDFs
        st.header("üì§ –ó–∞–≥—Ä—É–∑–∏—Ç—å PDF –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
        # in your sidebar, after the uploader:
        uploaded = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ PDF", 
            type=["pdf"], 
            accept_multiple_files=True,
            key="pdf_uploader"
        )

        # only run once per upload event
        if uploaded and not st.session_state.get("upload_processed", False):
            # save all files
            for file in uploaded:
                save_path = os.path.join(env_vars["DATA_PATH"], file.name)
                with open(save_path, "wb") as f:
                    f.write(file.getbuffer())

            st.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(uploaded)} —Ñ–∞–π–ª(–æ–≤). –ü–µ—Ä–µ—Å—Ç—Ä–∞–∏–≤–∞—é –∏–Ω–¥–µ–∫—Å‚Ä¶")
            st.session_state.upload_processed = True

            # now rebuild once
            rebuild_vector_store(env_vars)


    # Initialize chat history
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Display chat messages from history on app rerun
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Initialize RAG system
    if vector_store_exists:
        try:
            vector_store = get_vector_store(env_vars["CHROMA_PATH"])
            rag_chain = create_rag_chain(vector_store, 'gpt-3.5-turbo', temperature=0)
            
            # Accept user input
            if prompt := st.chat_input("–ó–∞–¥–∞–π—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å..."):
                # Add user message to chat history
                st.session_state.messages.append({"role": "user", "content": prompt})
                
                # Display user message
                with st.chat_message("user"):
                    st.markdown(prompt)

                # Generate and display assistant response
                with st.chat_message("assistant"):
                    with st.spinner("..."):
                        try:
                            response = rag_chain.invoke(prompt)
                            st.markdown(response)
                            # Add assistant response to chat history
                            st.session_state.messages.append({"role": "assistant", "content": response})
                        except Exception as e:
                            error_msg = f"–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}"
                            st.error(error_msg)
                            st.session_state.messages.append({"role": "assistant", "content": error_msg})
        
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–∏—Å—Ç–µ–º—ã: {str(e)}")
    else:
        st.warning("‚ö†Ô∏è –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–æ–∑–¥–∞–π—Ç–µ –∏–Ω–¥–µ–∫—Å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")
        if st.button("üìö –°–æ–∑–¥–∞—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"):
            rebuild_vector_store(env_vars)

    # Clear chat button
    if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç"):
        st.session_state.messages = []
        st.rerun()

def rebuild_vector_store(env_vars):
    """Rebuild the vector store from scratch."""
    if not env_vars["DATA_PATH"] or not os.path.exists(env_vars["DATA_PATH"]):
        st.error("–ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é DATA_PATH.")
        return
    
    try:
        st.info("üîÑ –ù–∞—á–∏–Ω–∞—é –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π...")
        
        # Load documents
        st.info("üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ PDF –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        docs = load_all_documents(env_vars["DATA_PATH"])
        
        # Split documents
        st.info("‚úÇÔ∏è –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ —á–∞—Å—Ç–∏...")
        chunks = split_documents(docs)
        st.success(f"–°–æ–∑–¥–∞–Ω–æ {len(chunks)} —á–∞—Å—Ç–µ–π —Ç–µ–∫—Å—Ç–∞")
        
        # Get embedding function
        embedding_function = get_embedding_function()
        
        # Index documents
        st.info("üîç –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞...")
        vector_store = index_documents(chunks, embedding_function, env_vars["CHROMA_PATH"])
        
        st.success("‚úÖ –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞!")
        st.balloons()
        
        # Clear cache to reload the vector store
        st.cache_resource.clear()
        st.rerun()
        
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {str(e)}")

if __name__ == "__main__":
    main()